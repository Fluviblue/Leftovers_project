# import libraries
import urllib2
from bs4 import BeautifulSoup
from gtts import gTTS # speech reproduction part
import os # speech reproduction
import json
# specify the url
quote_page = 'https://www.admin.ch/opc/en/classified-compilation/19110009/index.html#indexni1'

# query the website and return the html to the variable 'page'
page = urllib2.urlopen(quote_page)

# parse the html using beautiful soap and store in variable `soup`
soup = BeautifulSoup(page, 'html.parser')
print(type(soup))
# Take out the <div> of name and get its value
name_box = soup.find('h1', attrs={'class': 'title smallh1'})
print(name_box)

division = name_box.text.strip() # strip() is used to remove starting and trailing
print(division)

name_box = soup.find('h2', attrs={'class': 'title'})
print(name_box)

title = name_box.text.strip()
print(title)

name_box = soup.find('h3', attrs={'class': 'title'})
print(name_box)

section = name_box.text.strip()
print(section)

name_box = soup.find('h5')
print(name_box)

a1 = name_box.text.strip()
print(a1)

name_box = soup.find('div', attrs={'class': 'collapseableArticle'})
print(name_box)

a2 = name_box.text.strip()
print(a2)

def scrape_admin():

    # specify the url
    quote_page = 'https://www.admin.ch/opc/en/classified-compilation/19110009/index.html#indexni1'

    list_articles = soup.find_all("h5")
    list_content = soup.find_all("div", attrs = {"class" : "collapseableArticle"})
    print("got the list")

    list_of_articles = []

    x = 0
    for i in range (0, (len(list_articles) - 1)):  # exclude last article it has different format

        articles = {
            "article_name" : list_articles[i].text.strip(), #.decode('utf-8', 'ignore').encode('utf-8'),   # name of the article
            "article_number" : list_articles[i].text.strip().split(" ")[1],
            "article_content" : list_content[i].text.strip().split('1', 1)[-1]
        }

        list_of_articles.append(articles)
        print(x)
        x = x +1
    return list_of_articles


list_of_articles = scrape_admin()

search_word= "shareholder"  # link to voice HERE




list_of_results=[]
list_of_articles_numbers= []

for article in list_of_articles:

    if search_word in article["article_content"].lower().split(" "):
        list_of_results.append(article)
        list_of_articles_numbers.append(article["article_number"])


with open('scrape_admin.txt', 'w') as file:
    file.write(json.dumps(list_of_articles_numbers))
    file.close()

# Language in which you want to convert
language = 'en'

# Passing the text and language to the engine,
# here we have marked slow=False. Which tells
# the module that the converted audio should
# have a high speed
answer = "Your search word appears in total of " + str(len(list_of_articles_numbers)) + " articles among them are , article " + ", article ,".join(list_of_articles_numbers[0:2]) + " For an overview of the whole list of articles, please check the file scrape admin.txt"

myobj = gTTS(text= answer, lang=language, slow=False)

# Saving the converted audio in a mp3 file named
# welcome
myobj.save("welcome.mp3")
# Playing the converted file
os.system("mpg321 welcome.mp3")
print("Done")
